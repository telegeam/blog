---  
layout: post  
title: "[리뷰] 머신러닝을 활용한 웹 최적화"  
subtitle: "A/B 테스트, 메타휴리스틱, 슬롯머신 알고리즘에서 베이즈 최적화까지"  
categories: review  
tags: review book ML 머신러닝 A/B테스트 베이즈통계 확률 조합 분해 휴리스틱 테스트 웹최적화      
comments: true  
header-img: img/review/review-book-ml-web-optimization-1.png
---  
  
> `한빛미디어` 출판사의 `"머신러닝을 활용한 웹 최적화(이쓰카 슈헤이 저/김연수 역)"`를 읽고 작성한 리뷰입니다.  

![표지](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-1.png)  

---

A/B 테스트를 중심으로 통계 및 머신러닝을 활용하여 `웹사이트 최적화 기법`을 다루는 책이다. `연구` 성과를 일목요연하게 잘 정리하고 있고, `실전`에 적용하는데 필요한 고민과 해법이 같이 담겨 있다.

읽다보면 `매우 간단한 예제` 2개만으로 통계가 실전에서 어떻게 활용되는지 생생하게 접할 수 있다. 통계, 베이즈 추론 등에 숨겨진 개념을 실용적으로 끌어내는 방법을 비롯해 해당 분야의 연구 성과가 잘 정리되어 있어 실전에 적용할 만한 `연결고리`를 찾을 수 있다는 점도 장점이다.

책은 크게 2개의 예제를 중심으로 살이 붙어나가는 방식이기에 이를 중심으로 책의 내용과 배운점 및 장점을 요약해 본다.

---

* __예제1 : 앨리스와 밥의 A/B 테스트__  
  아래 그림은 앨리스와 밥이 상품 소개 페이지의 `자료 요청 버튼의 클릭율을 높이기 위하여`, 두 가지 디자인 A, B안을 준비한 후 노출 횟수 및 클릭 횟수를 측정한 결과이다. 클릭률이 우연히 동일하게 나왔지만 각 횟수가 다르기에 B안을 선택해야 한다고 결론을 내릴 수 있을까?
  ![예제1](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-2.png)  

  저자는 이 예제를 활용하여 웹사이트 최적화에 필요한 `기본 지식`을 정리한다. 확률 변수, 베르누이 시행, 확률 분포, 확률 분포의 파라미터, 정규화, 확률의 덧셈정리를 활용한 주변화(marginalization), 베이즈 업데이트를 활용한 사후 분포 시각화 등이 그것이다.
  ![사후분포](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-3.png)  

  그 중 사후 분포를 `정량적으로 평가하기 위한 방법` 2가지가 소개되는데 이 부분부터 웹사이트 최적화에 유용한 기법들이 본격적으로 소개되기 시작한다. 하나는 시행 반복을 통한 통계 모델링을 활용하여 분포를 추정하는 방법이고, 다른 하나는 사후 분포에 나타난 베타 분포를 활용한 방식인데 후자가 중요한 방식이다.

  먼저 후자 방식의 기초 통계량을 활용하는 방법이 소개되고 그 중 클릭율 사후 분포의 `HDI` - 확률 변수의 값이 높은 확률로 나타나는 구간 - 를 구하여 확률 질량이 큰 순서대로 상윗값을 반환하는 hmv 메서드를 만들어 "디자인 B안의 클릭율은 5%보다 높다."와 같은 가설을 만든다. 그 과정을 도식화하면 아래 그림과 같다. 
  ![HDI 가설](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-4.png)  

  이어서 A안의 클릭율과 B안의 클릭율의 차이인 파생 변수를 생성해보는 등 추가 시도를 거치는데 큰 확률이라는 값이 95%면 충분할 지, ROPE 폭과 같이 검증하고자 하는 가설을 정량적 평가로 변환하는 과정 등 실무에서 공유되어야 할 도메인 측면에 대한 고민도 담겨 있어 유용했다.

  여기까지가 통계와 웹최적화의 기본이었다면 2장 부터는 `MCMC`(마르코프 연쇄 몬테카를로 알고리즘)을 활용한다. 초기값은 최적의 파라미터 주위에 근접하도록 상태를 전이시키지만 이런 부분이 영향을 미치지 않도록 어느 정도 탐색이 진행된 뒤의 샘플을 얻는다. `PyMC3` 모듈을 활용하여 MCMC를 시각화하여 볼 수 있어 이해에 도움이 된다.

  특히 개인적으로는 가능도 함수의 분포인 베르누리 분포, 카테고리컬 분포, 이항 분포, 다항 분포와 신념(믿음)의 분포인 베타 분포, 디리클레 분포의 총체적인 관계를 정리해 볼 수 있어 만족스러웠다. 그동안 통계학에서 다루는 분포 대부분의 개념은 잘 숙지하고 있었지만 `분포 간의 변화와 관계`가 늘 궁금했는데 앨리스와 밥의 문제로 변수를 최소화 한 접근법 덕분에 비교적 명쾌하게 이해할 수 있었다.

  여기서 끝났어도 충분히 만족스러웠는데 하나 더 저자에게 고마움을 느낀 부분이 있다. 2장의 마무리 단계에서 `NHST(귀무가설 유의성 검증)과 베이즈 추론 간 통계적 가설 검증을 비교`해본다. 통계학 비전공자라 볼 때 마다 헷갈린 부분인데 이 책을 통해 감을 잡을 수 있었다. 
  ![두가지통계가설검증](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-5.png)  

  두 검증의 차이는 일단 기본적으로 자유도에 차이가 있다. NHST는 잘 알려진 분포만 활용한다는 한계가 있지만 검정 통계량을 신뢰할만하다. 반면 베이즈 접근 방식의 경우 앞서 예제와 같이 HDI를 비교 평가 할 수 있어 유연한 가설 검증이 가능했다. 하지만 적절한 사전 분포를 설계해야 한다는 제약 조건이 따르며 적응 데이터 분석 및 과적합 문제를 안고 있다는 사실로 정리해 볼 수 있었다. 

  사실 딥러닝을 먼저 시작한 나로써는 데이터가 많은 요즘 같은 시대에 검정, 추정을 실전에서 어떻게 활용하는지 늘 궁금했었고, 나아가 베이즈 추론과 사후 분포의 위력을 체감하기 어려웠는데 앨리스와 밥의 A/B 테스트와 같이 심플한 예제 덕분에 통계에 숨은 개념을 현실로 끌어내는데 큰 도움이 되었다. 이어질 두 번째 예제는 보다 어렵지만 나 같은 통계 하수는 1 ~ 2장만으로도 충분히 만족스러운 책이라고 평하고 싶다. 

---

* __예제2 : 조합형 4가지 디지안 시안 테스트__  
  제목은 어려워 보여도 이 역시 너무 간단한 예제이다. 아래 그림과 같이 시안 A,B,C,D 중 어떤 시안이 가장 뛰어날지 판단하는 문제이다. 위 예제1과 다른 점이 있다면 A,B는 그림이 같고, C,D는 버튼 문구가 다르다. 즉, 그림과 문구 간 조합이라는 요소가 존재하는 예제이다. 예제1은 개념을 익히기에는 좋은 예제이지만 실전에서 바로 활용하기는 어렵기에 예제2릍 통해 실전에 한 걸음 다가갈 수 있는 셈이다.
  ![예제2](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-6.png)  

  이 예제에서는 무엇보다 `통계 모델링`을 구체적으로 진행하는 방법이 소개되어 있어 유익했다. 예제1에서 배웠던 분포를 활용하여 이미지 변경에 따른 클릭율, 버튼 변경에 따른 클릭율, 베이스라인 클릭율 등 새로운 파생 변수를 도입한 후 로짓 함수 및 정규 분포를 활용하여 아래와 같이 최종 클릭율을 예측하는 모델을 만든다. 
  ![통계모델링](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-7.png)  

  이어서 요소의 조합에 의해 발생하는 `교호 작용`을 파악하고 모델에 교호 작용항을 추가한다. 이는 통계 기본에 해당하는 다중 공선성의 문제인데 교호작용을 어디까지 고려해야 할 지 생각해 볼 수 있는 좋은 기회였다. 4장에서는 해결책 중의 하나로 메타휴리스틱을 접목해본다. 
  ![메타휴리스틱](https://telegeam.github.io/assets/img/review/review-book-ml-web-optimization-8.png)  

  오른쪽 그림과 같이 접근하면 교호작용을 고려하거나 최적 변수 선택의 고만이 필요없다. A*알고리즘과 같이 목적지와 현 위치 사이의 추정거리를 휴리스틱으로 도입하는 셈이다. 이를 책에서는 언덕 오르기 알고리즘(Hill Climbing)이라고 정리하고 있다. 

  생긴 것이 딥러닝의 손실함수 경사하강법 문제와 비슷해 보인다 싶었는데 역시나 여기에서도 `국소 최적문제`가 등장했다. 이를 해결하고자 마치 SGD처럼 확률적 언덕 오르기 알고리즘, 온도 파라미터를 도입한 시뮬레이티드 어닐링, 교차율을 도입한 유전 알고리즘 등이 소개되는데 하나 하나 괜찮은 아이디어였다. 딥러닝이 통계와 얼마나 밀접한지 실감할 수 있었다.

  5장에서는 보다 실전에서 고민할 만한 사항이 등장한다. 테스트 중에 발생하는 손실, 기간 등에 대한 문제도 다룬다. 즉, 강화학습에서 흔히 볼 수 있는 다중 슬롯머신 `탐색과 활용 딜레마`가 웹페이지 최적화에도 등장하는 문제임을 알 수 있다. 이를 해결하기 위한 방법으로 Epsilon-Greedy, 시뮬레이티드 어닐링 Epsilon-Greedy, Softmax, 톰슨 샘플링, UCB 등의 아이디어가 소개된다.

  5장이 다소 연구적인 느낌의 정리였다면 6장은 5장에서 배운 연구 성과를 실전에 접목해보는 형태를 띈다. 즉, 눈 앞의 슬롯머신이 변하듯 `개인화` 구현의 문제로 넘어간다. MCMC를 베이즈 선형회귀에 접목하는 방법에서 연구 성과를 실전에 적용하는 방법론을 배울 수 있었다. 5장에서 배운 UCB를 응용해서 LinUCB를 구현해내는 과정은 머리속에 떠오른 아이디어를 어떻게 기존 연구에 연결할 수 있는지 그 경계선을 느끼게 해줬다. 

---

그 외에도 7장에서 배운 가우스 과정을 톰슨 샘플링에 적용한 GP-TS 알고리즘은 UCB에 아이디어를 살을 붙여 가는 방법을 알게 해줬다. 덕분에 읽으며 개인적으로 괜찮은 아이디어가 떠올랐는데 이를 접목해보고 논문을 써봐야겠다는 생각이 들었다. 이처럼 생소한 분야에 연구적 커넥팅을 가능하게 해준 다는 점은 이 책의 큰 장점 중 하나이다. 

8장에는 웹 최적화 분야에 앞으로 필요한 기술들이 소개되는데 오토인코더가 등장해서 신선했다. 다양한 AI 분야가 존재하지만 상호 영역을 잘 알아두고 조합한다면 어떤 분야에서든 멋진 아이디어가 파생될 수 있겠다는 생각이 들었다. 

적어도 내 수준에서는 이 책에서 너무도 많은 것을 배울 수 있었다. 위에서 언급했듯 통계가 실전에 어떻게 적용되는지 너무 심플한 예제로 통계학에 숨어있는 지식을 생생하게 느낄 수 있게 해준 점, 
저자 특유의 웹 최적화 분야 연구 성과 전달력 덕분에 아이디어를 연구 혹은 실전에 적용하는 연결고리를 얻게 해준 점 등 큰 도움을 받았다. 

리뷰를 통해 저자, 역자, 편집자 분들께 진심으로 감사의 말씀을 전하고 싶다. 웹최적화 뿐만 아니라 통계나 머신러닝에 관심있는 독자에게 꼭 추천하고 싶은 책이다.

---

* [책소개 - 머신러닝을 활용한 웹 최적화](http://www.yes24.com/Product/Goods/101972896)

> 한빛미디어 "나는 리뷰어다" 활동을 위해서 책을 제공받아 작성된 서평입니다.